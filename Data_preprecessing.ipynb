{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des donnes distribuées sur plusieurs fichiers csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_user=pd.read_csv('prediction_log/user_info.csv')\n",
    "df_course=pd.read_csv('prediction_log/course_info.csv')\n",
    "df_train_log=pd.read_csv('prediction_log/train_log.csv')\n",
    "df_train_truth=pd.read_csv('prediction_log/train_truth.csv')\n",
    "df_test_log=pd.read_csv('prediction_log/test_log.csv')\n",
    "df_test_truth=pd.read_csv('prediction_log/test_truth.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_user dtypes user_id        int64\n",
      "gender        object\n",
      "education     object\n",
      "birth        float64\n",
      "dtype: object\n",
      "df_course dtypes id             object\n",
      "course_id      object\n",
      "start          object\n",
      "end            object\n",
      "course_type     int64\n",
      "category       object\n",
      "dtype: object\n",
      "df_train_log dtypes enroll_id      int64\n",
      "username       int64\n",
      "course_id     object\n",
      "session_id    object\n",
      "action        object\n",
      "object        object\n",
      "time          object\n",
      "dtype: object\n",
      "df_train_truth dtypes enroll_id    int64\n",
      "truth        int64\n",
      "dtype: object\n",
      "df_test_log dtypes enroll_id      int64\n",
      "username       int64\n",
      "course_id     object\n",
      "session_id    object\n",
      "action        object\n",
      "object        object\n",
      "time          object\n",
      "dtype: object\n",
      "df_test_truth dtypes enroll_id    int64\n",
      "truth        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print( \"df_user dtypes\",df_user.dtypes)\n",
    "print(\"df_course dtypes\",df_course.dtypes)\n",
    "print(\"df_train_log dtypes\",df_train_log.dtypes)\n",
    "print(\"df_train_truth dtypes\",df_train_truth.dtypes)\n",
    "print(\"df_test_log dtypes\",df_test_log.dtypes)\n",
    "print(\"df_test_truth dtypes\",df_test_truth.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Vérification des valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs manquantes par dataset :\n",
      "df_user :\n",
      " user_id            0\n",
      "gender       8420796\n",
      "education    9298955\n",
      "birth        9145726\n",
      "dtype: int64\n",
      "df_course :\n",
      " id                0\n",
      "course_id         0\n",
      "start             0\n",
      "end             533\n",
      "course_type       0\n",
      "category       4956\n",
      "dtype: int64\n",
      "df_train_log :\n",
      " enroll_id           0\n",
      "username            0\n",
      "course_id           0\n",
      "session_id          0\n",
      "action              0\n",
      "object        7695279\n",
      "time                0\n",
      "dtype: int64\n",
      "df_train_truth :\n",
      " enroll_id    0\n",
      "truth        0\n",
      "dtype: int64\n",
      "df_test_log :\n",
      " enroll_id           0\n",
      "username            0\n",
      "course_id           0\n",
      "session_id          0\n",
      "action              0\n",
      "object        3314724\n",
      "time                0\n",
      "dtype: int64\n",
      "df_test_truth :\n",
      " enroll_id    0\n",
      "truth        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Valeurs manquantes par dataset :\")\n",
    "print(\"df_user :\\n\", df_user.isnull().sum())\n",
    "print(\"df_course :\\n\", df_course.isnull().sum())\n",
    "print(\"df_train_log :\\n\", df_train_log.isnull().sum())\n",
    "print(\"df_train_truth :\\n\", df_train_truth.isnull().sum())\n",
    "print(\"df_test_log :\\n\", df_test_log.isnull().sum())\n",
    "print(\"df_test_truth :\\n\", df_test_truth.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9627148\n",
      "user_id            0\n",
      "gender       8420796\n",
      "education    9298955\n",
      "birth        9145726\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(len(df_user['user_id'].unique()))\n",
    "print((df_user.isnull().sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69823"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_log['username'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'utilisateurs restants dans df_user_filtered : 77083\n"
     ]
    }
   ],
   "source": [
    "# Liste des utilisateurs dans les logs d'entraînement et de test\n",
    "user_ids_in_logs = set(df_train_log['username'].unique()).union(set(df_test_log['username'].unique()))\n",
    "\n",
    "# Filtrage de df_user pour ne garder que ces utilisateurs\n",
    "df_user_filtered = df_user[df_user['user_id'].isin(set(df_train_log['username'].unique()).union(set(df_test_log['username'].unique())))]\n",
    "\n",
    "# Affichage du nombre de lignes après filtrage\n",
    "print(\"Nombre d'utilisateurs restants dans df_user_filtered :\", len(df_user_filtered))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56909"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_log['object'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_user :\n",
      " user_id          0\n",
      "gender       48664\n",
      "education    57731\n",
      "birth        60711\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"df_user :\\n\", df_user.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_user=pd.read_csv('prediction_log/user_info.csv')\n",
    "df_course=pd.read_csv('prediction_log/course_info.csv')\n",
    "df_train_log=pd.read_csv('prediction_log/train_log.csv')\n",
    "df_train_truth=pd.read_csv('prediction_log/train_truth.csv')\n",
    "df_test_log=pd.read_csv('prediction_log/test_log.csv')\n",
    "df_test_truth=pd.read_csv('prediction_log/test_truth.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>birth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>631</td>\n",
       "      <td>male</td>\n",
       "      <td>High</td>\n",
       "      <td>1997.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2631</td>\n",
       "      <td>male</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>1990.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4231</td>\n",
       "      <td>male</td>\n",
       "      <td>Associate</td>\n",
       "      <td>1991.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id gender   education   birth\n",
       "0      631   male        High  1997.0\n",
       "1     2631   male  Bachelor's  1990.0\n",
       "2     4231   male   Associate  1991.0"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>course_type</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6561</td>\n",
       "      <td>course-v1:CPVS+CPVS-HDLSC001+20160901</td>\n",
       "      <td>2016-11-16 08:00:00</td>\n",
       "      <td>2016-12-31 23:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5557</td>\n",
       "      <td>course-v1:SCUT+144282+201709</td>\n",
       "      <td>2016-09-01 00:00:00</td>\n",
       "      <td>2017-02-28 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9433</td>\n",
       "      <td>course-v1:ZK+06093+J</td>\n",
       "      <td>2018-01-01 08:00:00</td>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8320</td>\n",
       "      <td>course-v1:nuist+001+2016-T1</td>\n",
       "      <td>2017-03-01 18:30:00</td>\n",
       "      <td>2017-07-01 23:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>231</td>\n",
       "      <td>FUDAN/CFD004/2014.9-2015.1</td>\n",
       "      <td>2014-09-10 08:00:00</td>\n",
       "      <td>2015-09-10 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                              course_id                start  \\\n",
       "0  6561  course-v1:CPVS+CPVS-HDLSC001+20160901  2016-11-16 08:00:00   \n",
       "1  5557           course-v1:SCUT+144282+201709  2016-09-01 00:00:00   \n",
       "2  9433                   course-v1:ZK+06093+J  2018-01-01 08:00:00   \n",
       "3  8320            course-v1:nuist+001+2016-T1  2017-03-01 18:30:00   \n",
       "4   231             FUDAN/CFD004/2014.9-2015.1  2014-09-10 08:00:00   \n",
       "\n",
       "                   end  course_type category  \n",
       "0  2016-12-31 23:30:00            0      NaN  \n",
       "1  2017-02-28 00:00:00            0      NaN  \n",
       "2  2020-01-01 00:00:00            0      NaN  \n",
       "3  2017-07-01 23:30:00            0      NaN  \n",
       "4  2015-09-10 00:00:00            0      NaN  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_course.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enroll_id</th>\n",
       "      <th>username</th>\n",
       "      <th>course_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>action</th>\n",
       "      <th>object</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>772</td>\n",
       "      <td>5981</td>\n",
       "      <td>course-v1:TsinghuaX+70800232X+2015_T2</td>\n",
       "      <td>d8a9b787fa69063c34c73b9c29190b1c</td>\n",
       "      <td>click_about</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-27T15:42:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>772</td>\n",
       "      <td>5981</td>\n",
       "      <td>course-v1:TsinghuaX+70800232X+2015_T2</td>\n",
       "      <td>d8a9b787fa69063c34c73b9c29190b1c</td>\n",
       "      <td>click_info</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-27T15:43:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>773</td>\n",
       "      <td>1544995</td>\n",
       "      <td>course-v1:TsinghuaX+70800232X+2015_T2</td>\n",
       "      <td>2f02b86eb3ea2cbf0be11385a8dc62e5</td>\n",
       "      <td>pause_video</td>\n",
       "      <td>3dac5590435e43b3a65a9ae7426c16db</td>\n",
       "      <td>2015-10-19T19:37:42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   enroll_id  username                              course_id  \\\n",
       "0        772      5981  course-v1:TsinghuaX+70800232X+2015_T2   \n",
       "1        772      5981  course-v1:TsinghuaX+70800232X+2015_T2   \n",
       "2        773   1544995  course-v1:TsinghuaX+70800232X+2015_T2   \n",
       "\n",
       "                         session_id       action  \\\n",
       "0  d8a9b787fa69063c34c73b9c29190b1c  click_about   \n",
       "1  d8a9b787fa69063c34c73b9c29190b1c   click_info   \n",
       "2  2f02b86eb3ea2cbf0be11385a8dc62e5  pause_video   \n",
       "\n",
       "                             object                 time  \n",
       "0                               NaN  2015-09-27T15:42:59  \n",
       "1                               NaN  2015-09-27T15:43:12  \n",
       "2  3dac5590435e43b3a65a9ae7426c16db  2015-10-19T19:37:42  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_log.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_log['course_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_course['category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_course = df_course[df_course['course_id'].isin(set(df_train_log['course_id'].unique()).union(set(df_test_log['course_id'].unique())))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_course['course_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_course.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>course_type</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5735</td>\n",
       "      <td>course-v1:NJU+010101+2016_T1</td>\n",
       "      <td>2016-03-28 08:00:00</td>\n",
       "      <td>2017-02-15 23:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>social science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2070</td>\n",
       "      <td>course-v1:TsinghuaX+00510663X+2015_T2</td>\n",
       "      <td>2015-10-12 12:00:00</td>\n",
       "      <td>2016-01-16 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>557</td>\n",
       "      <td>TsinghuaX/10450034_1X/2015_T2</td>\n",
       "      <td>2015-11-02 08:00:00</td>\n",
       "      <td>2016-02-03 20:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>7272</td>\n",
       "      <td>course-v1:TsinghuaX+00612643X+2016_T2</td>\n",
       "      <td>2016-10-10 09:00:00</td>\n",
       "      <td>2016-12-31 00:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>749</td>\n",
       "      <td>MITx/15_390x_2015_T1/2015_T1</td>\n",
       "      <td>2015-07-03 08:00:00</td>\n",
       "      <td>2015-09-15 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6313</th>\n",
       "      <td>2889</td>\n",
       "      <td>course-v1:TsinghuaX+MOOC102+2015_T2</td>\n",
       "      <td>2015-10-26 08:00:00</td>\n",
       "      <td>2016-01-24 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6315</th>\n",
       "      <td>6768</td>\n",
       "      <td>course-v1:TsinghuaX+00691153X+2016_T2</td>\n",
       "      <td>2016-09-12 08:00:00</td>\n",
       "      <td>2017-01-16 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>philosophy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6344</th>\n",
       "      <td>1565</td>\n",
       "      <td>course-v1:TsinghuaX+80512073X_2015_2+2015_T2</td>\n",
       "      <td>2015-10-09 09:00:00</td>\n",
       "      <td>2016-06-30 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6390</th>\n",
       "      <td>6771</td>\n",
       "      <td>course-v1:TsinghuaX+30700313X+2016_T2</td>\n",
       "      <td>2016-09-07 08:00:00</td>\n",
       "      <td>2016-12-23 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>social science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6401</th>\n",
       "      <td>6792</td>\n",
       "      <td>course-v1:TsinghuaX+80512073X+2016--T2</td>\n",
       "      <td>2016-09-02 08:00:00</td>\n",
       "      <td>2016-12-23 23:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>economics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                     course_id                start  \\\n",
       "38    5735                  course-v1:NJU+010101+2016_T1  2016-03-28 08:00:00   \n",
       "59    2070         course-v1:TsinghuaX+00510663X+2015_T2  2015-10-12 12:00:00   \n",
       "60     557                 TsinghuaX/10450034_1X/2015_T2  2015-11-02 08:00:00   \n",
       "86    7272         course-v1:TsinghuaX+00612643X+2016_T2  2016-10-10 09:00:00   \n",
       "220    749                  MITx/15_390x_2015_T1/2015_T1  2015-07-03 08:00:00   \n",
       "...    ...                                           ...                  ...   \n",
       "6313  2889           course-v1:TsinghuaX+MOOC102+2015_T2  2015-10-26 08:00:00   \n",
       "6315  6768         course-v1:TsinghuaX+00691153X+2016_T2  2016-09-12 08:00:00   \n",
       "6344  1565  course-v1:TsinghuaX+80512073X_2015_2+2015_T2  2015-10-09 09:00:00   \n",
       "6390  6771         course-v1:TsinghuaX+30700313X+2016_T2  2016-09-07 08:00:00   \n",
       "6401  6792        course-v1:TsinghuaX+80512073X+2016--T2  2016-09-02 08:00:00   \n",
       "\n",
       "                      end  course_type        category  \n",
       "38    2017-02-15 23:30:00            0  social science  \n",
       "59    2016-01-16 00:00:00            0        business  \n",
       "60    2016-02-03 20:00:00            0         biology  \n",
       "86    2016-12-31 00:30:00            0      literature  \n",
       "220   2015-09-15 00:00:00            0        business  \n",
       "...                   ...          ...             ...  \n",
       "6313  2016-01-24 00:00:00            0       education  \n",
       "6315  2017-01-16 00:00:00            0      philosophy  \n",
       "6344  2016-06-30 00:00:00            0        business  \n",
       "6390  2016-12-23 00:00:00            0  social science  \n",
       "6401  2016-12-23 23:30:00            0       economics  \n",
       "\n",
       "[247 rows x 6 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayoub\\AppData\\Local\\Temp\\ipykernel_37544\\3256214770.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_course['category'].fillna('Unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_course['category'].fillna('Unknown', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "course_id      0\n",
       "start          0\n",
       "end            0\n",
       "course_type    0\n",
       "category       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_course.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prétraitement du Dataset df_user (Profil des utilisateurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id\n",
       "0      631\n",
       "1     2631"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Supprimer les colonnes inutiles\n",
    "df_user = df_user[['user_id']]\n",
    "df_user.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = df_user[df_user['user_id'].isin(set(df_train_log['username'].unique()).union(set(df_test_log['username'].unique())))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>298031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>437831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>453031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id\n",
       "146   298031\n",
       "210   437831\n",
       "217   453031"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>course_type</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5735</td>\n",
       "      <td>course-v1:NJU+010101+2016_T1</td>\n",
       "      <td>2016-03-28 08:00:00</td>\n",
       "      <td>2017-02-15 23:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>social science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2070</td>\n",
       "      <td>course-v1:TsinghuaX+00510663X+2015_T2</td>\n",
       "      <td>2015-10-12 12:00:00</td>\n",
       "      <td>2016-01-16 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>557</td>\n",
       "      <td>TsinghuaX/10450034_1X/2015_T2</td>\n",
       "      <td>2015-11-02 08:00:00</td>\n",
       "      <td>2016-02-03 20:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>biology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                              course_id                start  \\\n",
       "38  5735           course-v1:NJU+010101+2016_T1  2016-03-28 08:00:00   \n",
       "59  2070  course-v1:TsinghuaX+00510663X+2015_T2  2015-10-12 12:00:00   \n",
       "60   557          TsinghuaX/10450034_1X/2015_T2  2015-11-02 08:00:00   \n",
       "\n",
       "                    end  course_type        category  \n",
       "38  2017-02-15 23:30:00            0  social science  \n",
       "59  2016-01-16 00:00:00            0        business  \n",
       "60  2016-02-03 20:00:00            0         biology  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_course.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prétraitement du Dataset df_course (Informations des cours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_course = df_course[['course_id', 'category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_course['category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>course-v1:NJU+010101+2016_T1</td>\n",
       "      <td>social science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>course-v1:TsinghuaX+00510663X+2015_T2</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                course_id        category\n",
       "38           course-v1:NJU+010101+2016_T1  social science\n",
       "59  course-v1:TsinghuaX+00510663X+2015_T2        business"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_course.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enroll_id</th>\n",
       "      <th>username</th>\n",
       "      <th>course_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>action</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>772</td>\n",
       "      <td>5981</td>\n",
       "      <td>course-v1:TsinghuaX+70800232X+2015_T2</td>\n",
       "      <td>d8a9b787fa69063c34c73b9c29190b1c</td>\n",
       "      <td>click_about</td>\n",
       "      <td>2015-09-27T15:42:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>772</td>\n",
       "      <td>5981</td>\n",
       "      <td>course-v1:TsinghuaX+70800232X+2015_T2</td>\n",
       "      <td>d8a9b787fa69063c34c73b9c29190b1c</td>\n",
       "      <td>click_info</td>\n",
       "      <td>2015-09-27T15:43:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   enroll_id  username                              course_id  \\\n",
       "0        772      5981  course-v1:TsinghuaX+70800232X+2015_T2   \n",
       "1        772      5981  course-v1:TsinghuaX+70800232X+2015_T2   \n",
       "\n",
       "                         session_id       action                 time  \n",
       "0  d8a9b787fa69063c34c73b9c29190b1c  click_about  2015-09-27T15:42:59  \n",
       "1  d8a9b787fa69063c34c73b9c29190b1c   click_info  2015-09-27T15:43:12  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_log = df_train_log[['enroll_id' ,'username', 'course_id', 'session_id' , 'action', 'time']]\n",
    "df_test_log = df_test_log[['enroll_id' ,'username', 'course_id', 'session_id' , 'action', 'time']]\n",
    "\n",
    "df_train_log.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs manquantes dans df_user :\n",
      "user_id    0\n",
      "dtype: int64\n",
      "\n",
      "Valeurs manquantes dans df_course :\n",
      "course_id    0\n",
      "category     0\n",
      "dtype: int64\n",
      "\n",
      "Valeurs manquantes dans df_train_log :\n",
      "enroll_id     0\n",
      "username      0\n",
      "course_id     0\n",
      "session_id    0\n",
      "action        0\n",
      "time          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Valeurs manquantes dans df_user :\")\n",
    "print(df_user.isnull().sum())\n",
    "\n",
    "print(\"\\nValeurs manquantes dans df_course :\")\n",
    "print(df_course.isnull().sum())\n",
    "\n",
    "print(\"\\nValeurs manquantes dans df_train_log :\")\n",
    "print(df_train_log.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types de données dans df_user:\n",
      "user_id    int64\n",
      "dtype: object\n",
      "\n",
      "Types de données dans df_course:\n",
      "course_id    object\n",
      "category     object\n",
      "dtype: object\n",
      "\n",
      "Types de données dans df_train_log:\n",
      "enroll_id      int64\n",
      "username       int64\n",
      "course_id     object\n",
      "session_id    object\n",
      "action        object\n",
      "time          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Types de données dans df_user:\")\n",
    "print(df_user.dtypes)\n",
    "\n",
    "print(\"\\nTypes de données dans df_course:\")\n",
    "print(df_course.dtypes)\n",
    "\n",
    "print(\"\\nTypes de données dans df_train_log:\")\n",
    "print(df_train_log.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayoub\\AppData\\Local\\Temp\\ipykernel_37544\\3923769906.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_log['time'] = pd.to_datetime(df_train_log['time'])\n"
     ]
    }
   ],
   "source": [
    "df_train_log['time'] = pd.to_datetime(df_train_log['time'])\n",
    "df_test_log['time'] = pd.to_datetime(df_test_log['time'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  fusion des Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_log_course = df_train_log.merge(df_course, on='course_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69823"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_log_course['username'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_log_course = df_test_log.merge(df_course, on='course_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enroll_id     0\n",
       "username      0\n",
       "course_id     0\n",
       "session_id    0\n",
       "action        0\n",
       "time          0\n",
       "category      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_log_course.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_log_course.to_csv(\"prediction_log/df_test_log_course.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_log_course.to_csv(\"prediction_log/df_train_log_course.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enroll_id</th>\n",
       "      <th>username</th>\n",
       "      <th>course_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>action</th>\n",
       "      <th>time</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>772</td>\n",
       "      <td>5981</td>\n",
       "      <td>course-v1:TsinghuaX+70800232X+2015_T2</td>\n",
       "      <td>d8a9b787fa69063c34c73b9c29190b1c</td>\n",
       "      <td>click_about</td>\n",
       "      <td>2015-09-27 15:42:59</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>772</td>\n",
       "      <td>5981</td>\n",
       "      <td>course-v1:TsinghuaX+70800232X+2015_T2</td>\n",
       "      <td>d8a9b787fa69063c34c73b9c29190b1c</td>\n",
       "      <td>click_info</td>\n",
       "      <td>2015-09-27 15:43:12</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>773</td>\n",
       "      <td>1544995</td>\n",
       "      <td>course-v1:TsinghuaX+70800232X+2015_T2</td>\n",
       "      <td>2f02b86eb3ea2cbf0be11385a8dc62e5</td>\n",
       "      <td>pause_video</td>\n",
       "      <td>2015-10-19 19:37:42</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   enroll_id  username                              course_id  \\\n",
       "0        772      5981  course-v1:TsinghuaX+70800232X+2015_T2   \n",
       "1        772      5981  course-v1:TsinghuaX+70800232X+2015_T2   \n",
       "2        773   1544995  course-v1:TsinghuaX+70800232X+2015_T2   \n",
       "\n",
       "                         session_id       action                time category  \n",
       "0  d8a9b787fa69063c34c73b9c29190b1c  click_about 2015-09-27 15:42:59      art  \n",
       "1  d8a9b787fa69063c34c73b9c29190b1c   click_info 2015-09-27 15:43:12      art  \n",
       "2  2f02b86eb3ea2cbf0be11385a8dc62e5  pause_video 2015-10-19 19:37:42      art  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_log_course.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exploration dataset after doing feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayoub\\AppData\\Local\\Temp\\ipykernel_25584\\3475775026.py:2: DtypeWarning: Columns (0,1,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_final = pd.read_csv('prediction_log/dfspark_train_log_final.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df_final = pd.read_csv('prediction_log/dfspark_train_log_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>enroll_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>action</th>\n",
       "      <th>time</th>\n",
       "      <th>category</th>\n",
       "      <th>session_duration</th>\n",
       "      <th>session_gap</th>\n",
       "      <th>action_count</th>\n",
       "      <th>action_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>136060</td>\n",
       "      <td>c4d05fdd4af11ea45bb4623b2b6fa2c4</td>\n",
       "      <td>TsinghuaX/60510102X/_</td>\n",
       "      <td>close_courseware</td>\n",
       "      <td>2015-10-12T17:34:13.000Z</td>\n",
       "      <td>business</td>\n",
       "      <td>10468</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.001051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>136060</td>\n",
       "      <td>c4d05fdd4af11ea45bb4623b2b6fa2c4</td>\n",
       "      <td>TsinghuaX/60510102X/_</td>\n",
       "      <td>seek_video</td>\n",
       "      <td>2015-10-12T14:40:02.000Z</td>\n",
       "      <td>business</td>\n",
       "      <td>10468</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.001051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>136060</td>\n",
       "      <td>c4d05fdd4af11ea45bb4623b2b6fa2c4</td>\n",
       "      <td>TsinghuaX/60510102X/_</td>\n",
       "      <td>seek_video</td>\n",
       "      <td>2015-10-12T14:40:03.000Z</td>\n",
       "      <td>business</td>\n",
       "      <td>10468</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.001051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>136060</td>\n",
       "      <td>c4d05fdd4af11ea45bb4623b2b6fa2c4</td>\n",
       "      <td>TsinghuaX/60510102X/_</td>\n",
       "      <td>seek_video</td>\n",
       "      <td>2015-10-12T14:40:05.000Z</td>\n",
       "      <td>business</td>\n",
       "      <td>10468</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.001051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>136060</td>\n",
       "      <td>c4d05fdd4af11ea45bb4623b2b6fa2c4</td>\n",
       "      <td>TsinghuaX/60510102X/_</td>\n",
       "      <td>pause_video</td>\n",
       "      <td>2015-10-12T14:40:11.000Z</td>\n",
       "      <td>business</td>\n",
       "      <td>10468</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.001051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29165542</th>\n",
       "      <td>6881054</td>\n",
       "      <td>292631</td>\n",
       "      <td>ddcf4ebe15e59e3845ec1bea33d048ae</td>\n",
       "      <td>course-v1:TsinghuaX+90640012X+2017_T1</td>\n",
       "      <td>click_info</td>\n",
       "      <td>2017-03-26T12:31:32.000Z</td>\n",
       "      <td>foreign language</td>\n",
       "      <td>90208</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29165543</th>\n",
       "      <td>6881054</td>\n",
       "      <td>292631</td>\n",
       "      <td>ddcf4ebe15e59e3845ec1bea33d048ae</td>\n",
       "      <td>course-v1:TsinghuaX+90640012X+2017_T1</td>\n",
       "      <td>click_courseware</td>\n",
       "      <td>2017-03-26T12:31:34.000Z</td>\n",
       "      <td>foreign language</td>\n",
       "      <td>90208</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29165544</th>\n",
       "      <td>6881054</td>\n",
       "      <td>292631</td>\n",
       "      <td>ddcf4ebe15e59e3845ec1bea33d048ae</td>\n",
       "      <td>course-v1:TsinghuaX+90640012X+2017_T1</td>\n",
       "      <td>load_video</td>\n",
       "      <td>2017-03-26T12:31:35.000Z</td>\n",
       "      <td>foreign language</td>\n",
       "      <td>90208</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29165545</th>\n",
       "      <td>6881054</td>\n",
       "      <td>292631</td>\n",
       "      <td>ddcf4ebe15e59e3845ec1bea33d048ae</td>\n",
       "      <td>course-v1:TsinghuaX+90640012X+2017_T1</td>\n",
       "      <td>pause_video</td>\n",
       "      <td>2017-03-26T12:31:28.000Z</td>\n",
       "      <td>foreign language</td>\n",
       "      <td>90208</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29165546</th>\n",
       "      <td>6881054</td>\n",
       "      <td>292631</td>\n",
       "      <td>ddcf4ebe15e59e3845ec1bea33d048ae</td>\n",
       "      <td>course-v1:TsinghuaX+90640012X+2017_T1</td>\n",
       "      <td>play_video</td>\n",
       "      <td>2017-03-26T12:31:40.000Z</td>\n",
       "      <td>foreign language</td>\n",
       "      <td>90208</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29165547 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         username enroll_id                        session_id  \\\n",
       "0               5    136060  c4d05fdd4af11ea45bb4623b2b6fa2c4   \n",
       "1               5    136060  c4d05fdd4af11ea45bb4623b2b6fa2c4   \n",
       "2               5    136060  c4d05fdd4af11ea45bb4623b2b6fa2c4   \n",
       "3               5    136060  c4d05fdd4af11ea45bb4623b2b6fa2c4   \n",
       "4               5    136060  c4d05fdd4af11ea45bb4623b2b6fa2c4   \n",
       "...           ...       ...                               ...   \n",
       "29165542  6881054    292631  ddcf4ebe15e59e3845ec1bea33d048ae   \n",
       "29165543  6881054    292631  ddcf4ebe15e59e3845ec1bea33d048ae   \n",
       "29165544  6881054    292631  ddcf4ebe15e59e3845ec1bea33d048ae   \n",
       "29165545  6881054    292631  ddcf4ebe15e59e3845ec1bea33d048ae   \n",
       "29165546  6881054    292631  ddcf4ebe15e59e3845ec1bea33d048ae   \n",
       "\n",
       "                                      course_id            action  \\\n",
       "0                         TsinghuaX/60510102X/_  close_courseware   \n",
       "1                         TsinghuaX/60510102X/_        seek_video   \n",
       "2                         TsinghuaX/60510102X/_        seek_video   \n",
       "3                         TsinghuaX/60510102X/_        seek_video   \n",
       "4                         TsinghuaX/60510102X/_       pause_video   \n",
       "...                                         ...               ...   \n",
       "29165542  course-v1:TsinghuaX+90640012X+2017_T1        click_info   \n",
       "29165543  course-v1:TsinghuaX+90640012X+2017_T1  click_courseware   \n",
       "29165544  course-v1:TsinghuaX+90640012X+2017_T1        load_video   \n",
       "29165545  course-v1:TsinghuaX+90640012X+2017_T1       pause_video   \n",
       "29165546  course-v1:TsinghuaX+90640012X+2017_T1        play_video   \n",
       "\n",
       "                              time          category session_duration  \\\n",
       "0         2015-10-12T17:34:13.000Z          business            10468   \n",
       "1         2015-10-12T14:40:02.000Z          business            10468   \n",
       "2         2015-10-12T14:40:03.000Z          business            10468   \n",
       "3         2015-10-12T14:40:05.000Z          business            10468   \n",
       "4         2015-10-12T14:40:11.000Z          business            10468   \n",
       "...                            ...               ...              ...   \n",
       "29165542  2017-03-26T12:31:32.000Z  foreign language            90208   \n",
       "29165543  2017-03-26T12:31:34.000Z  foreign language            90208   \n",
       "29165544  2017-03-26T12:31:35.000Z  foreign language            90208   \n",
       "29165545  2017-03-26T12:31:28.000Z  foreign language            90208   \n",
       "29165546  2017-03-26T12:31:40.000Z  foreign language            90208   \n",
       "\n",
       "         session_gap action_count action_frequency  \n",
       "0                  0           11         0.001051  \n",
       "1                  0           11         0.001051  \n",
       "2                  0           11         0.001051  \n",
       "3                  0           11         0.001051  \n",
       "4                  0           11         0.001051  \n",
       "...              ...          ...              ...  \n",
       "29165542           0           24         0.000266  \n",
       "29165543           0           24         0.000266  \n",
       "29165544           0           24         0.000266  \n",
       "29165545           0           24         0.000266  \n",
       "29165546           0           24         0.000266  \n",
       "\n",
       "[29165547 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number unique de session_id 292481\n",
      "number unique de username 71499\n",
      "number unique de course_id 248\n",
      "number unique de action 23\n",
      "number unique de session_duration 99046\n",
      "number unique de action_frequency 186649\n",
      "number unique de session_gap 158291\n"
     ]
    }
   ],
   "source": [
    "print('number unique de session_id',len(df_final['session_id'].unique()))\n",
    "print('number unique de username',len(df_final['username'].unique()))\n",
    "print('number unique de course_id',len(df_final['course_id'].unique()))\n",
    "print('number unique de action',len(df_final['action'].unique()))\n",
    "print('number unique de session_duration',len(df_final['session_duration'].unique()))\n",
    "print('number unique de action_frequency',len(df_final['action_frequency'].unique()))\n",
    "print('number unique de session_gap',len(df_final['session_gap'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['username', 'enroll_id', 'session_id', 'course_id', 'action', 'time',\n",
       "       'category', 'session_duration', 'session_gap', 'action_count',\n",
       "       'action_frequency'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────────────── skimpy summary ─────────────────────────────────────────────────╮\n",
       "│ <span style=\"font-style: italic\">          Data Summary          </span> <span style=\"font-style: italic\">      Data Types       </span>                                                        │\n",
       "│ ┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┓ ┏━━━━━━━━━━━━━┳━━━━━━━┓                                                        │\n",
       "│ ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Dataframe         </span>┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Values   </span>┃ ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Column Type </span>┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Count </span>┃                                                        │\n",
       "│ ┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━┩ ┡━━━━━━━━━━━━━╇━━━━━━━┩                                                        │\n",
       "│ │ Number of rows    │ 29165547 │ │ string      │ 5     │                                                        │\n",
       "│ │ Number of columns │ 5        │ └─────────────┴───────┘                                                        │\n",
       "│ └───────────────────┴──────────┘                                                                                │\n",
       "│ <span style=\"font-style: italic\">                                                    string                                                    </span>  │\n",
       "│ ┏━━━━━━━━━━━┳━━━━┳━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓  │\n",
       "│ ┃<span style=\"font-weight: bold\">           </span>┃<span style=\"font-weight: bold\">    </span>┃<span style=\"font-weight: bold\">      </span>┃<span style=\"font-weight: bold\">           </span>┃<span style=\"font-weight: bold\">           </span>┃<span style=\"font-weight: bold\">           </span>┃<span style=\"font-weight: bold\">           </span>┃<span style=\"font-weight: bold\"> chars per </span>┃<span style=\"font-weight: bold\"> words per  </span>┃<span style=\"font-weight: bold\"> total     </span>┃  │\n",
       "│ ┃<span style=\"font-weight: bold\"> column    </span>┃<span style=\"font-weight: bold\"> NA </span>┃<span style=\"font-weight: bold\"> NA % </span>┃<span style=\"font-weight: bold\"> shortest  </span>┃<span style=\"font-weight: bold\"> longest   </span>┃<span style=\"font-weight: bold\"> min       </span>┃<span style=\"font-weight: bold\"> max       </span>┃<span style=\"font-weight: bold\"> row       </span>┃<span style=\"font-weight: bold\"> row        </span>┃<span style=\"font-weight: bold\"> words     </span>┃  │\n",
       "│ ┡━━━━━━━━━━━╇━━━━╇━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━┩  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">session_i</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">session_i</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">c4d05fdd4</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">0000031ff</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">session_i</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">       32</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">         1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 29165547</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">d        </span> │    │      │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">d        </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">af11ea45b</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">11d4cb663</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">d        </span> │           │            │           │  │\n",
       "│ │           │    │      │           │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">b4623b2b6</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">ee0c5a6b5</span> │           │           │            │           │  │\n",
       "│ │           │    │      │           │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">fa2c4    </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">5eaad    </span> │           │           │            │           │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">course_id</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">course_id</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">course-v1</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">CAU/08112</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">course_id</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     36.6</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">         1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 29165547</span> │  │\n",
       "│ │           │    │      │           │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">:UC_Berke</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">500x/2015</span> │           │           │            │           │  │\n",
       "│ │           │    │      │           │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">leyX+ColW</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">_T2      </span> │           │           │            │           │  │\n",
       "│ │           │    │      │           │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">ri2_1x_20</span> │           │           │           │            │           │  │\n",
       "│ │           │    │      │           │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">15_T1+201</span> │           │           │           │            │           │  │\n",
       "│ │           │    │      │           │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">6_TS     </span> │           │           │           │            │           │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">action   </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">action   </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">problem_c</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">action   </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">stop_vide</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">       12</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">         1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 29165547</span> │  │\n",
       "│ │           │    │      │           │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">heck_inco</span> │           │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">o        </span> │           │            │           │  │\n",
       "│ │           │    │      │           │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">rrect    </span> │           │           │           │            │           │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">time     </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">time     </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">2015-10-1</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">2015-06-0</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">time     </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">       24</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">         1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 29165547</span> │  │\n",
       "│ │           │    │      │           │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">2T17:34:1</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">4T16:37:5</span> │           │           │            │           │  │\n",
       "│ │           │    │      │           │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">3.000Z   </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">0.000Z   </span> │           │           │            │           │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">category </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">art      </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">foreign  </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Unknown  </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">social   </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     9.94</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">       1.2</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 35950384</span> │  │\n",
       "│ │           │    │      │           │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">language </span> │           │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">science  </span> │           │            │           │  │\n",
       "│ └───────────┴────┴──────┴───────────┴───────────┴───────────┴───────────┴───────────┴────────────┴───────────┘  │\n",
       "╰────────────────────────────────────────────────────── End ──────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────────────── skimpy summary ─────────────────────────────────────────────────╮\n",
       "│ \u001b[3m          Data Summary          \u001b[0m \u001b[3m      Data Types       \u001b[0m                                                        │\n",
       "│ ┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┓ ┏━━━━━━━━━━━━━┳━━━━━━━┓                                                        │\n",
       "│ ┃\u001b[1;36m \u001b[0m\u001b[1;36mDataframe        \u001b[0m\u001b[1;36m \u001b[0m┃\u001b[1;36m \u001b[0m\u001b[1;36mValues  \u001b[0m\u001b[1;36m \u001b[0m┃ ┃\u001b[1;36m \u001b[0m\u001b[1;36mColumn Type\u001b[0m\u001b[1;36m \u001b[0m┃\u001b[1;36m \u001b[0m\u001b[1;36mCount\u001b[0m\u001b[1;36m \u001b[0m┃                                                        │\n",
       "│ ┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━┩ ┡━━━━━━━━━━━━━╇━━━━━━━┩                                                        │\n",
       "│ │ Number of rows    │ 29165547 │ │ string      │ 5     │                                                        │\n",
       "│ │ Number of columns │ 5        │ └─────────────┴───────┘                                                        │\n",
       "│ └───────────────────┴──────────┘                                                                                │\n",
       "│ \u001b[3m                                                    string                                                    \u001b[0m  │\n",
       "│ ┏━━━━━━━━━━━┳━━━━┳━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓  │\n",
       "│ ┃\u001b[1m           \u001b[0m┃\u001b[1m    \u001b[0m┃\u001b[1m      \u001b[0m┃\u001b[1m           \u001b[0m┃\u001b[1m           \u001b[0m┃\u001b[1m           \u001b[0m┃\u001b[1m           \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mchars per\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mwords per \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtotal    \u001b[0m\u001b[1m \u001b[0m┃  │\n",
       "│ ┃\u001b[1m \u001b[0m\u001b[1mcolumn   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA %\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mshortest \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mlongest  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmin      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmax      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mrow      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mrow       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mwords    \u001b[0m\u001b[1m \u001b[0m┃  │\n",
       "│ ┡━━━━━━━━━━━╇━━━━╇━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━┩  │\n",
       "│ │ \u001b[38;5;141msession_i\u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[38;5;141msession_i\u001b[0m │ \u001b[38;5;141mc4d05fdd4\u001b[0m │ \u001b[38;5;141m0000031ff\u001b[0m │ \u001b[38;5;141msession_i\u001b[0m │ \u001b[36m       32\u001b[0m │ \u001b[36m         1\u001b[0m │ \u001b[36m 29165547\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141md        \u001b[0m │    │      │ \u001b[38;5;141md        \u001b[0m │ \u001b[38;5;141maf11ea45b\u001b[0m │ \u001b[38;5;141m11d4cb663\u001b[0m │ \u001b[38;5;141md        \u001b[0m │           │            │           │  │\n",
       "│ │           │    │      │           │ \u001b[38;5;141mb4623b2b6\u001b[0m │ \u001b[38;5;141mee0c5a6b5\u001b[0m │           │           │            │           │  │\n",
       "│ │           │    │      │           │ \u001b[38;5;141mfa2c4    \u001b[0m │ \u001b[38;5;141m5eaad    \u001b[0m │           │           │            │           │  │\n",
       "│ │ \u001b[38;5;141mcourse_id\u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[38;5;141mcourse_id\u001b[0m │ \u001b[38;5;141mcourse-v1\u001b[0m │ \u001b[38;5;141mCAU/08112\u001b[0m │ \u001b[38;5;141mcourse_id\u001b[0m │ \u001b[36m     36.6\u001b[0m │ \u001b[36m         1\u001b[0m │ \u001b[36m 29165547\u001b[0m │  │\n",
       "│ │           │    │      │           │ \u001b[38;5;141m:UC_Berke\u001b[0m │ \u001b[38;5;141m500x/2015\u001b[0m │           │           │            │           │  │\n",
       "│ │           │    │      │           │ \u001b[38;5;141mleyX+ColW\u001b[0m │ \u001b[38;5;141m_T2      \u001b[0m │           │           │            │           │  │\n",
       "│ │           │    │      │           │ \u001b[38;5;141mri2_1x_20\u001b[0m │           │           │           │            │           │  │\n",
       "│ │           │    │      │           │ \u001b[38;5;141m15_T1+201\u001b[0m │           │           │           │            │           │  │\n",
       "│ │           │    │      │           │ \u001b[38;5;141m6_TS     \u001b[0m │           │           │           │            │           │  │\n",
       "│ │ \u001b[38;5;141maction   \u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[38;5;141maction   \u001b[0m │ \u001b[38;5;141mproblem_c\u001b[0m │ \u001b[38;5;141maction   \u001b[0m │ \u001b[38;5;141mstop_vide\u001b[0m │ \u001b[36m       12\u001b[0m │ \u001b[36m         1\u001b[0m │ \u001b[36m 29165547\u001b[0m │  │\n",
       "│ │           │    │      │           │ \u001b[38;5;141mheck_inco\u001b[0m │           │ \u001b[38;5;141mo        \u001b[0m │           │            │           │  │\n",
       "│ │           │    │      │           │ \u001b[38;5;141mrrect    \u001b[0m │           │           │           │            │           │  │\n",
       "│ │ \u001b[38;5;141mtime     \u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[38;5;141mtime     \u001b[0m │ \u001b[38;5;141m2015-10-1\u001b[0m │ \u001b[38;5;141m2015-06-0\u001b[0m │ \u001b[38;5;141mtime     \u001b[0m │ \u001b[36m       24\u001b[0m │ \u001b[36m         1\u001b[0m │ \u001b[36m 29165547\u001b[0m │  │\n",
       "│ │           │    │      │           │ \u001b[38;5;141m2T17:34:1\u001b[0m │ \u001b[38;5;141m4T16:37:5\u001b[0m │           │           │            │           │  │\n",
       "│ │           │    │      │           │ \u001b[38;5;141m3.000Z   \u001b[0m │ \u001b[38;5;141m0.000Z   \u001b[0m │           │           │            │           │  │\n",
       "│ │ \u001b[38;5;141mcategory \u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[38;5;141mart      \u001b[0m │ \u001b[38;5;141mforeign  \u001b[0m │ \u001b[38;5;141mUnknown  \u001b[0m │ \u001b[38;5;141msocial   \u001b[0m │ \u001b[36m     9.94\u001b[0m │ \u001b[36m       1.2\u001b[0m │ \u001b[36m 35950384\u001b[0m │  │\n",
       "│ │           │    │      │           │ \u001b[38;5;141mlanguage \u001b[0m │           │ \u001b[38;5;141mscience  \u001b[0m │           │            │           │  │\n",
       "│ └───────────┴────┴──────┴───────────┴───────────┴───────────┴───────────┴───────────┴────────────┴───────────┘  │\n",
       "╰────────────────────────────────────────────────────── End ──────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skimpy import skim\n",
    "skim(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['username', 'enroll_id', 'session_id', 'course_id', 'action', 'time',\n",
       "       'category', 'session_duration', 'session_gap', 'action_count',\n",
       "       'action_frequency'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Vérification avant conversion:\n",
      "username            object\n",
      "enroll_id           object\n",
      "session_id          object\n",
      "course_id           object\n",
      "action              object\n",
      "time                object\n",
      "category            object\n",
      "session_duration    object\n",
      "session_gap         object\n",
      "action_count        object\n",
      "action_frequency    object\n",
      "dtype: object\n",
      "\n",
      " Vérification après conversion:\n",
      "username                      object\n",
      "enroll_id                     object\n",
      "session_id                    object\n",
      "course_id                     object\n",
      "action                        object\n",
      "time                         float64\n",
      "session_duration               int64\n",
      "session_gap                    int64\n",
      "action_count                   int64\n",
      "action_frequency             float64\n",
      "category_Unknown             float64\n",
      "category_art                 float64\n",
      "category_biology             float64\n",
      "category_business            float64\n",
      "category_chemistry           float64\n",
      "category_computer            float64\n",
      "category_economics           float64\n",
      "category_education           float64\n",
      "category_electrical          float64\n",
      "category_engineering         float64\n",
      "category_foreign language    float64\n",
      "category_history             float64\n",
      "category_literature          float64\n",
      "category_math                float64\n",
      "category_medicine            float64\n",
      "category_philosophy          float64\n",
      "category_physics             float64\n",
      "category_social science      float64\n",
      "dtype: object\n",
      "\n",
      "Vérification des premières lignes :\n",
      "     username enroll_id                        session_id  \\\n",
      "8826     1921      2331  0e914c1dff2f62c1a9e2550aa4cbc0e4   \n",
      "8827     1921      2331  0e914c1dff2f62c1a9e2550aa4cbc0e4   \n",
      "8828     1921      2331  0e914c1dff2f62c1a9e2550aa4cbc0e4   \n",
      "8829     1921      2331  0e914c1dff2f62c1a9e2550aa4cbc0e4   \n",
      "8830     1921      2331  0e914c1dff2f62c1a9e2550aa4cbc0e4   \n",
      "\n",
      "                                  course_id       action          time  \\\n",
      "8826  course-v1:TsinghuaX+70800232X+2015_T2  click_about  1.445429e+09   \n",
      "8827  course-v1:TsinghuaX+70800232X+2015_T2  click_about  1.445429e+09   \n",
      "8828  course-v1:TsinghuaX+70800232X+2015_T2  click_about  1.445434e+09   \n",
      "8829  course-v1:TsinghuaX+70800232X+2015_T2  click_about  1.445434e+09   \n",
      "8830  course-v1:TsinghuaX+70800232X+2015_T2   click_info  1.445434e+09   \n",
      "\n",
      "      session_duration  session_gap  action_count  action_frequency  ...  \\\n",
      "8826              9139       682715            15          0.001641  ...   \n",
      "8827              9139       682715            15          0.001641  ...   \n",
      "8828              9139       682715            15          0.001641  ...   \n",
      "8829              9139       682715            15          0.001641  ...   \n",
      "8830              9139       682715            15          0.001641  ...   \n",
      "\n",
      "      category_electrical  category_engineering  category_foreign language  \\\n",
      "8826                  0.0                   0.0                        0.0   \n",
      "8827                  0.0                   0.0                        0.0   \n",
      "8828                  0.0                   0.0                        0.0   \n",
      "8829                  0.0                   0.0                        0.0   \n",
      "8830                  0.0                   0.0                        0.0   \n",
      "\n",
      "      category_history  category_literature  category_math  category_medicine  \\\n",
      "8826               0.0                  0.0            0.0                0.0   \n",
      "8827               0.0                  0.0            0.0                0.0   \n",
      "8828               0.0                  0.0            0.0                0.0   \n",
      "8829               0.0                  0.0            0.0                0.0   \n",
      "8830               0.0                  0.0            0.0                0.0   \n",
      "\n",
      "      category_philosophy  category_physics  category_social science  \n",
      "8826                  0.0               0.0                      0.0  \n",
      "8827                  0.0               0.0                      0.0  \n",
      "8828                  0.0               0.0                      0.0  \n",
      "8829                  0.0               0.0                      0.0  \n",
      "8830                  0.0               0.0                      0.0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def preprocess_dataframe(df):\n",
    "    \"\"\"  Convertit correctement les types du DataFrame avant la construction du graphe. \"\"\"\n",
    "    \n",
    "    print(\"\\n  Vérification avant conversion:\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "    if 'time' in df.columns:\n",
    "        df['time'] = pd.to_datetime(df['time'], errors='coerce').astype('int64') / 1e9\n",
    "\n",
    "    if 'session_start' in df.columns:\n",
    "        df['session_start'] = pd.to_datetime(df['session_start'], errors='coerce').astype('int64') / 1e9\n",
    "    \n",
    "    numeric_columns = ['session_duration', 'session_gap', 'action_count', 'action_frequency']\n",
    "    for col in numeric_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)  # Assurer qu'il n'y a pas de NaN\n",
    "\n",
    "    if 'category' in df.columns:\n",
    "        df = pd.get_dummies(df, columns=['category'], dtype=float)\n",
    "\n",
    "    print(\"\\n Vérification après conversion:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    print(\"\\nVérification des premières lignes :\")\n",
    "    print(df.head())\n",
    "\n",
    "    return df\n",
    "\n",
    "df_active = preprocess_dataframe(df_active)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Vérification avant conversion:\n",
      "username                      object\n",
      "enroll_id                     object\n",
      "session_id                    object\n",
      "course_id                     object\n",
      "action                        object\n",
      "time                         float64\n",
      "session_duration               int64\n",
      "session_gap                    int64\n",
      "action_count                   int64\n",
      "action_frequency             float64\n",
      "category_Unknown             float64\n",
      "category_art                 float64\n",
      "category_biology             float64\n",
      "category_business            float64\n",
      "category_chemistry           float64\n",
      "category_computer            float64\n",
      "category_economics           float64\n",
      "category_education           float64\n",
      "category_electrical          float64\n",
      "category_engineering         float64\n",
      "category_foreign language    float64\n",
      "category_history             float64\n",
      "category_literature          float64\n",
      "category_math                float64\n",
      "category_medicine            float64\n",
      "category_philosophy          float64\n",
      "category_physics             float64\n",
      "category_social science      float64\n",
      "dtype: object\n",
      "\n",
      "    Vérification après conversion:\n",
      "username                      object\n",
      "enroll_id                     object\n",
      "session_id                    object\n",
      "course_id                     object\n",
      "action                        object\n",
      "time                         float64\n",
      "session_duration               int64\n",
      "session_gap                    int64\n",
      "action_count                   int64\n",
      "action_frequency             float64\n",
      "category_Unknown             float64\n",
      "category_art                 float64\n",
      "category_biology             float64\n",
      "category_business            float64\n",
      "category_chemistry           float64\n",
      "category_computer            float64\n",
      "category_economics           float64\n",
      "category_education           float64\n",
      "category_electrical          float64\n",
      "category_engineering         float64\n",
      "category_foreign language    float64\n",
      "category_history             float64\n",
      "category_literature          float64\n",
      "category_math                float64\n",
      "category_medicine            float64\n",
      "category_philosophy          float64\n",
      "category_physics             float64\n",
      "category_social science      float64\n",
      "dtype: object\n",
      "\n",
      "  Vérification des premières lignes :\n",
      "     username enroll_id                        session_id  \\\n",
      "8826     1921      2331  0e914c1dff2f62c1a9e2550aa4cbc0e4   \n",
      "8827     1921      2331  0e914c1dff2f62c1a9e2550aa4cbc0e4   \n",
      "8828     1921      2331  0e914c1dff2f62c1a9e2550aa4cbc0e4   \n",
      "8829     1921      2331  0e914c1dff2f62c1a9e2550aa4cbc0e4   \n",
      "8830     1921      2331  0e914c1dff2f62c1a9e2550aa4cbc0e4   \n",
      "\n",
      "                                  course_id       action      time  \\\n",
      "8826  course-v1:TsinghuaX+70800232X+2015_T2  click_about  1.445429   \n",
      "8827  course-v1:TsinghuaX+70800232X+2015_T2  click_about  1.445429   \n",
      "8828  course-v1:TsinghuaX+70800232X+2015_T2  click_about  1.445434   \n",
      "8829  course-v1:TsinghuaX+70800232X+2015_T2  click_about  1.445434   \n",
      "8830  course-v1:TsinghuaX+70800232X+2015_T2   click_info  1.445434   \n",
      "\n",
      "      session_duration  session_gap  action_count  action_frequency  ...  \\\n",
      "8826              9139       682715            15          0.001641  ...   \n",
      "8827              9139       682715            15          0.001641  ...   \n",
      "8828              9139       682715            15          0.001641  ...   \n",
      "8829              9139       682715            15          0.001641  ...   \n",
      "8830              9139       682715            15          0.001641  ...   \n",
      "\n",
      "      category_electrical  category_engineering  category_foreign language  \\\n",
      "8826                  0.0                   0.0                        0.0   \n",
      "8827                  0.0                   0.0                        0.0   \n",
      "8828                  0.0                   0.0                        0.0   \n",
      "8829                  0.0                   0.0                        0.0   \n",
      "8830                  0.0                   0.0                        0.0   \n",
      "\n",
      "      category_history  category_literature  category_math  category_medicine  \\\n",
      "8826               0.0                  0.0            0.0                0.0   \n",
      "8827               0.0                  0.0            0.0                0.0   \n",
      "8828               0.0                  0.0            0.0                0.0   \n",
      "8829               0.0                  0.0            0.0                0.0   \n",
      "8830               0.0                  0.0            0.0                0.0   \n",
      "\n",
      "      category_philosophy  category_physics  category_social science  \n",
      "8826                  0.0               0.0                      0.0  \n",
      "8827                  0.0               0.0                      0.0  \n",
      "8828                  0.0               0.0                      0.0  \n",
      "8829                  0.0               0.0                      0.0  \n",
      "8830                  0.0               0.0                      0.0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def preprocess_dataframe(df):\n",
    "    \"\"\"   Convertit correctement les types du DataFrame avant la construction du graphe. \"\"\"\n",
    "    \n",
    "    print(\"\\n  Vérification avant conversion:\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "    #   1️Conversion des timestamps en `float` (UNIX timestamp)\n",
    "    if 'time' in df.columns:\n",
    "        df['time'] = pd.to_datetime(df['time'], errors='coerce').astype('int64') / 1e9\n",
    "\n",
    "    if 'session_start' in df.columns:\n",
    "        df['session_start'] = pd.to_datetime(df['session_start'], errors='coerce').astype('int64') / 1e9\n",
    "    \n",
    "    #     Conversion des colonnes contenant des nombres en `float`\n",
    "    numeric_columns = ['session_duration', 'session_gap', 'action_count', 'action_frequency']\n",
    "    for col in numeric_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)  # Assurer qu'il n'y a pas de NaN\n",
    "\n",
    "    #   Conversion des `category` en **one-hot encoding**\n",
    "    if 'category' in df.columns:\n",
    "        df = pd.get_dummies(df, columns=['category'], dtype=float)\n",
    "\n",
    "    print(\"\\n    Vérification après conversion:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    print(\"\\n  Vérification des premières lignes :\")\n",
    "    print(df.head())\n",
    "\n",
    "    return df\n",
    "\n",
    "#   Application du prétraitement avec vérification\n",
    "df_active = preprocess_dataframe(df_active)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "def build_pyg_graph(df):\n",
    "    data = HeteroData()\n",
    "\n",
    "    node_mapping = {node_type: {} for node_type in ['user', 'session', 'course', 'action']}\n",
    "    node_counters = {node_type: 0 for node_type in ['user', 'session', 'course', 'action']}\n",
    "\n",
    "    category_columns = [col for col in df.columns if col.startswith(\"category_\")]\n",
    "    num_courses = df['course_id'].nunique()\n",
    "    course_features = torch.zeros(num_courses, len(category_columns))  # One-hot matrix\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        user = row['username']\n",
    "        session = row['session_id']\n",
    "        course = row['course_id']\n",
    "        action = f\"{session}_{row['action']}\"\n",
    "\n",
    "        if user not in node_mapping['user']:\n",
    "            node_mapping['user'][user] = node_counters['user']\n",
    "            node_counters['user'] += 1\n",
    "\n",
    "        if session not in node_mapping['session']:\n",
    "            node_mapping['session'][session] = node_counters['session']\n",
    "            node_counters['session'] += 1\n",
    "\n",
    "        if course not in node_mapping['course']:\n",
    "            node_mapping['course'][course] = node_counters['course']\n",
    "            node_counters['course'] += 1\n",
    "\n",
    "            course_features[node_mapping['course'][course]] = torch.tensor(row[category_columns].astype(float).values, dtype=torch.float)\n",
    "\n",
    "        if action not in node_mapping['action']:\n",
    "            node_mapping['action'][action] = node_counters['action']\n",
    "            node_counters['action'] += 1\n",
    "\n",
    "    #   ... Adding node features to `HeteroData`\n",
    "    data['user'].num_nodes = node_counters['user']\n",
    "    data['session'].num_nodes = node_counters['session']\n",
    "    data['course'].num_nodes = node_counters['course']\n",
    "    data['action'].num_nodes = node_counters['action']\n",
    "\n",
    "    data['course'].x = course_features  # One-hot encoded categories\n",
    "\n",
    "    session_durations = torch.zeros(node_counters['session'])\n",
    "    for _, row in df.iterrows():\n",
    "        session_id = row['session_id']\n",
    "        if session_id in node_mapping['session']:\n",
    "            session_durations[node_mapping['session'][session_id]] = float(row['session_duration'])\n",
    "    data['session'].x = session_durations.view(-1, 1)  # Reshape for PyTorch compatibility\n",
    "\n",
    "    edge_types = {\n",
    "        ('user', 'ENROLLED_IN', 'course'): [],\n",
    "        ('user', 'PARTICIPATES_IN', 'session'): [],\n",
    "        ('session', 'HAS_ACTION', 'action'): [],\n",
    "        ('action', 'FOLLOWS', 'action'): [],\n",
    "        ('session', 'SESSION_GAP', 'session'): []\n",
    "    }\n",
    "\n",
    "    edge_weights = {\n",
    "        ('user', 'ENROLLED_IN', 'course'): [],\n",
    "        ('user', 'PARTICIPATES_IN', 'session'): [],\n",
    "        ('session', 'HAS_ACTION', 'action'): [],\n",
    "        ('action', 'FOLLOWS', 'action'): [],\n",
    "        ('session', 'SESSION_GAP', 'session'): []\n",
    "    }\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        u = node_mapping['user'][row['username']]\n",
    "        s = node_mapping['session'][row['session_id']]\n",
    "        c = node_mapping['course'][row['course_id']]\n",
    "        a = node_mapping['action'][f\"{row['session_id']}_{row['action']}\"]\n",
    "\n",
    "        edge_types[('user', 'ENROLLED_IN', 'course')].append((u, c))\n",
    "        edge_weights[('user', 'ENROLLED_IN', 'course')].append(float(row['action_count']))\n",
    "\n",
    "        edge_types[('user', 'PARTICIPATES_IN', 'session')].append((u, s))\n",
    "        edge_weights[('user', 'PARTICIPATES_IN', 'session')].append(float(row['session_duration']))\n",
    "\n",
    "        edge_types[('session', 'HAS_ACTION', 'action')].append((s, a))\n",
    "        edge_weights[('session', 'HAS_ACTION', 'action')].append(float(row['time']))\n",
    "\n",
    "    for edge_type, edge_list in edge_types.items():\n",
    "        if edge_list:\n",
    "            edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
    "            data[edge_type].edge_index = edge_index\n",
    "\n",
    "            edge_attr = torch.tensor([float(w) for w in edge_weights[edge_type]], dtype=torch.float).view(-1, 1)\n",
    "            data[edge_type].edge_attr = edge_attr\n",
    "\n",
    "    return data\n",
    "\n",
    "data_pyg = build_pyg_graph(df_active)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new graph construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Nombre total de nœuds: 214084\n",
      "  - user: 715 nœuds\n",
      "  - session: 26777 nœuds\n",
      "  - course: 247 nœuds\n",
      "  - action: 186345 nœuds\n",
      "  ('user', 'ENROLLED_IN', 'course'): torch.Size([2, 2270612])\n",
      "  ('user', 'PARTICIPATES_IN', 'session'): torch.Size([2, 2270612])\n",
      "  ('session', 'HAS_ACTION', 'action'): torch.Size([2, 2270612])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "def build_pyg_graph(df):\n",
    "    data = HeteroData()\n",
    "\n",
    "    node_mapping = {node_type: {} for node_type in ['user', 'session', 'course', 'action']}\n",
    "    node_counters = {node_type: 0 for node_type in ['user', 'session', 'course', 'action']}\n",
    "\n",
    "    #   Extraction des catégories pour `course`\n",
    "    category_columns = [col for col in df.columns if col.startswith(\"category_\")]\n",
    "    num_courses = df['course_id'].nunique()\n",
    "    course_features = torch.zeros(num_courses, len(category_columns))  # Matrice One-Hot\n",
    "\n",
    "    session_features = torch.zeros(df['session_id'].nunique(), 4)  # 4 Features pour sessions\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        user, session, course = row['username'], row['session_id'], row['course_id']\n",
    "        action = f\"{session}_{row['action']}\"\n",
    "\n",
    "        #   Création des nœuds\n",
    "        if user not in node_mapping['user']:\n",
    "            node_mapping['user'][user] = node_counters['user']\n",
    "            node_counters['user'] += 1\n",
    "\n",
    "        if session not in node_mapping['session']:\n",
    "            node_mapping['session'][session] = node_counters['session']\n",
    "            node_counters['session'] += 1\n",
    "\n",
    "        if course not in node_mapping['course']:\n",
    "            node_mapping['course'][course] = node_counters['course']\n",
    "            node_counters['course'] += 1\n",
    "            try:\n",
    "                course_features[node_mapping['course'][course]] = torch.tensor(row[category_columns].astype(float).values, dtype=torch.float)\n",
    "            except Exception as e:\n",
    "                print(f\"  Problème avec course {course}: {e}\")\n",
    "\n",
    "        if action not in node_mapping['action']:\n",
    "            node_mapping['action'][action] = node_counters['action']\n",
    "            node_counters['action'] += 1\n",
    "\n",
    "        #   Ajout des features pour `session.x`\n",
    "        session_idx = node_mapping['session'][session]\n",
    "        session_features[session_idx] = torch.tensor([\n",
    "            float(row['session_duration']),\n",
    "            float(row['session_gap']),\n",
    "            float(row['action_count']),\n",
    "            float(row['action_frequency'])\n",
    "        ], dtype=torch.float)\n",
    "\n",
    "    #   ... Ajout des features aux nœuds\n",
    "    data['user'].num_nodes = node_counters['user']\n",
    "    data['session'].num_nodes = node_counters['session']\n",
    "    data['course'].num_nodes = node_counters['course']\n",
    "    data['action'].num_nodes = node_counters['action']\n",
    "\n",
    "    data['course'].x = course_features\n",
    "    data['session'].x = session_features  # (N_sessions, 4)\n",
    "\n",
    "    #   5 Création des arêtes\n",
    "    edge_types = {\n",
    "        ('user', 'ENROLLED_IN', 'course'): [],\n",
    "        ('user', 'PARTICIPATES_IN', 'session'): [],\n",
    "        ('session', 'HAS_ACTION', 'action'): [],\n",
    "        ('action', 'FOLLOWS', 'action'): [],\n",
    "        ('session', 'SESSION_GAP', 'session'): []\n",
    "    }\n",
    "\n",
    "    edge_weights = {etype: [] for etype in edge_types}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        u, s, c = node_mapping['user'][row['username']], node_mapping['session'][row['session_id']], node_mapping['course'][row['course_id']]\n",
    "        a = node_mapping['action'][f\"{row['session_id']}_{row['action']}\"]\n",
    "\n",
    "        # Ajout des arêtes\n",
    "        edge_types[('user', 'ENROLLED_IN', 'course')].append((u, c))\n",
    "        edge_weights[('user', 'ENROLLED_IN', 'course')].append(float(row['action_count']))\n",
    "\n",
    "        edge_types[('user', 'PARTICIPATES_IN', 'session')].append((u, s))\n",
    "        edge_weights[('user', 'PARTICIPATES_IN', 'session')].append(float(row['session_duration']))\n",
    "\n",
    "        edge_types[('session', 'HAS_ACTION', 'action')].append((s, a))\n",
    "        edge_weights[('session', 'HAS_ACTION', 'action')].append(float(row['time']))\n",
    "\n",
    "    #     Conversion des arêtes en `torch.Tensor`\n",
    "    for edge_type, edge_list in edge_types.items():\n",
    "        if edge_list:\n",
    "            edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
    "            data[edge_type].edge_index = edge_index\n",
    "\n",
    "            edge_attr = torch.tensor([float(w) for w in edge_weights[edge_type]], dtype=torch.float).view(-1, 1)\n",
    "            data[edge_type].edge_attr = edge_attr\n",
    "\n",
    "    return data\n",
    "\n",
    "data_pyg = build_pyg_graph(df_active)\n",
    "\n",
    "#   Vérifications\n",
    "print(f\"  Nombre total de nœuds: {sum(data_pyg[node].num_nodes for node in data_pyg.node_types)}\")\n",
    "for node_type in data_pyg.node_types:\n",
    "    print(f\"  - {node_type}: {data_pyg[node_type].num_nodes} nœuds\")\n",
    "\n",
    "#   Vérification des dimensions des features\n",
    "for key in ['session', 'course']:\n",
    "    if key in data_pyg and hasattr(data_pyg[key], 'x'):\n",
    "        print(f\"  Features de {key}: {data_pyg[key].x.shape}\")\n",
    "\n",
    "#   Vérification des arêtes\n",
    "for edge in data_pyg.edge_types:\n",
    "    print(f\"  {edge}: {data_pyg[edge].edge_index.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  session n'a pas de features !\n",
      "  course n'a pas de features !\n"
     ]
    }
   ],
   "source": [
    "#   Vérification des dimensions des features\n",
    "for key in ['session', 'course']:\n",
    "    if key in data_pyg and hasattr(data_pyg[key], 'x'):\n",
    "        print(f\"  {key}.x shape: {data_pyg[key].x.shape}\")\n",
    "    else:\n",
    "        print(f\"  {key} n'a pas de features !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train_Test_Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "def split_graph(data, test_ratio=0.2, seed=42):\n",
    "    \"\"\"\n",
    "    Splits the graph into train and test sets while preserving edge structure.\n",
    "\n",
    "    Args:\n",
    "    - data (HeteroData): The full heterogeneous graph.\n",
    "    - test_ratio (float): Fraction of edges to use for testing.\n",
    "    - seed (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - train_data (HeteroData): The training graph.\n",
    "    - test_data (HeteroData): The test graph.\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    train_data = HeteroData()\n",
    "    test_data = HeteroData()\n",
    "\n",
    "    for node_type in data.node_types:\n",
    "        train_data[node_type].num_nodes = data[node_type].num_nodes\n",
    "        test_data[node_type].num_nodes = data[node_type].num_nodes\n",
    "\n",
    "        if 'x' in data[node_type]:\n",
    "            train_data[node_type].x = data[node_type].x.clone()\n",
    "            test_data[node_type].x = data[node_type].x.clone()\n",
    "\n",
    "    for edge_type in data.edge_types:\n",
    "        edge_index = data[edge_type].edge_index\n",
    "        num_edges = edge_index.shape[1]\n",
    "\n",
    "        # Shuffle indices\n",
    "        indices = np.arange(num_edges)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        num_test = int(test_ratio * num_edges)\n",
    "        test_indices = indices[:num_test]\n",
    "        train_indices = indices[num_test:]\n",
    "\n",
    "        # Assign edges to train and test graphs\n",
    "        train_data[edge_type].edge_index = edge_index[:, train_indices]\n",
    "        test_data[edge_type].edge_index = edge_index[:, test_indices]\n",
    "\n",
    "        if 'edge_attr' in data[edge_type]:\n",
    "            train_data[edge_type].edge_attr = data[edge_type].edge_attr[train_indices]\n",
    "            test_data[edge_type].edge_attr = data[edge_type].edge_attr[test_indices]\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "train_graph, test_graph = split_graph(data_pyg, test_ratio=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Graph Split Verification** \n",
      "\n",
      " **Node Counts in Train & Test Graphs:**\n",
      "  user: Train = 715, Test = 715\n",
      "  session: Train = 26777, Test = 26777\n",
      "  course: Train = 247, Test = 247\n",
      "  action: Train = 186345, Test = 186345\n",
      "\n",
      " **Edge Counts in Train & Test Graphs:**\n",
      "  ('user', 'ENROLLED_IN', 'course'): Train = 1816490, Test = 454122\n",
      "  ('user', 'PARTICIPATES_IN', 'session'): Train = 1816490, Test = 454122\n",
      "  ('session', 'HAS_ACTION', 'action'): Train = 1816490, Test = 454122\n",
      "\n",
      " **Edge Attribute Checks:**\n",
      "  ('user', 'ENROLLED_IN', 'course') | Train Attr Shape: torch.Size([1816490, 1]), Test Attr Shape: torch.Size([454122, 1])\n",
      "  ('user', 'PARTICIPATES_IN', 'session') | Train Attr Shape: torch.Size([1816490, 1]), Test Attr Shape: torch.Size([454122, 1])\n",
      "  ('session', 'HAS_ACTION', 'action') | Train Attr Shape: torch.Size([1816490, 1]), Test Attr Shape: torch.Size([454122, 1])\n",
      "\n",
      " **Checking for Data Leakage (overlapping edges)**\n",
      "  ('user', 'ENROLLED_IN', 'course') | Overlapping Edges: 5541 (should be 0)\n",
      "  ('user', 'PARTICIPATES_IN', 'session') | Overlapping Edges: 23445 (should be 0)\n",
      "  ('session', 'HAS_ACTION', 'action') | Overlapping Edges: 103231 (should be 0)\n"
     ]
    }
   ],
   "source": [
    "def check_graph_split(train_graph, test_graph):\n",
    "    print(\"\\n **Graph Split Verification** \")\n",
    "\n",
    "    print(\"\\n **Node Counts in Train & Test Graphs:**\")\n",
    "    for node_type in train_graph.node_types:\n",
    "        train_nodes = train_graph[node_type].num_nodes if hasattr(train_graph[node_type], 'num_nodes') else 0\n",
    "        test_nodes = test_graph[node_type].num_nodes if hasattr(test_graph[node_type], 'num_nodes') else 0\n",
    "        print(f\"  {node_type}: Train = {train_nodes}, Test = {test_nodes}\")\n",
    "\n",
    "    print(\"\\n **Edge Counts in Train & Test Graphs:**\")\n",
    "    for edge_type in train_graph.edge_types:\n",
    "        train_edges = train_graph[edge_type].edge_index.shape[1] if train_graph[edge_type].edge_index.numel() > 0 else 0\n",
    "        test_edges = test_graph[edge_type].edge_index.shape[1] if test_graph[edge_type].edge_index.numel() > 0 else 0\n",
    "        print(f\"  {edge_type}: Train = {train_edges}, Test = {test_edges}\")\n",
    "\n",
    "    print(\"\\n **Edge Attribute Checks:**\")\n",
    "    for edge_type in train_graph.edge_types:\n",
    "        if 'edge_attr' in train_graph[edge_type]:\n",
    "            print(f\"  {edge_type} | Train Attr Shape: {train_graph[edge_type].edge_attr.shape}, Test Attr Shape: {test_graph[edge_type].edge_attr.shape}\")\n",
    "\n",
    "    print(\"\\n **Checking for Data Leakage (overlapping edges)**\")\n",
    "    for edge_type in train_graph.edge_types:\n",
    "        train_edges_set = set(map(tuple, train_graph[edge_type].edge_index.T.tolist()))\n",
    "        test_edges_set = set(map(tuple, test_graph[edge_type].edge_index.T.tolist()))\n",
    "        overlap = train_edges_set.intersection(test_edges_set)\n",
    "        print(f\"  {edge_type} | Overlapping Edges: {len(overlap)} (should be 0)\")\n",
    "\n",
    "check_graph_split(train_graph, test_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Nombre de nœuds après split:\n",
      "  - user: 715 (train) | 715 (test)\n",
      "  - session: 26777 (train) | 26777 (test)\n",
      "  - course: 247 (train) | 247 (test)\n",
      "  - action: 186345 (train) | 186345 (test)\n",
      "\n",
      "  Nombre d'arêtes après split:\n",
      "  - ('user', 'ENROLLED_IN', 'course'): 1816490 (train) | 454122 (test)\n",
      "  - ('user', 'PARTICIPATES_IN', 'session'): 1816490 (train) | 454122 (test)\n",
      "  - ('session', 'HAS_ACTION', 'action'): 1816490 (train) | 454122 (test)\n",
      "\n",
      "  session features shape: torch.Size([26777, 1]) (train) | torch.Size([26777, 1]) (test)\n",
      "\n",
      "  course features shape: torch.Size([247, 18]) (train) | torch.Size([247, 18]) (test)\n",
      "\n",
      "  ('user', 'ENROLLED_IN', 'course') edge features shape: torch.Size([1816490, 1]) (train) | torch.Size([454122, 1]) (test)\n",
      "\n",
      "  ('user', 'PARTICIPATES_IN', 'session') edge features shape: torch.Size([1816490, 1]) (train) | torch.Size([454122, 1]) (test)\n",
      "\n",
      "  ('session', 'HAS_ACTION', 'action') edge features shape: torch.Size([1816490, 1]) (train) | torch.Size([454122, 1]) (test)\n"
     ]
    }
   ],
   "source": [
    "#   Vérification des nœuds\n",
    "print(\"  Nombre de nœuds après split:\")\n",
    "for node_type in train_graph.node_types:\n",
    "    print(f\"  - {node_type}: {train_graph[node_type].num_nodes} (train) | {test_graph[node_type].num_nodes} (test)\")\n",
    "\n",
    "#   Vérification des arêtes\n",
    "print(\"\\n  Nombre d'arêtes après split:\")\n",
    "for edge_type in train_graph.edge_types:\n",
    "    train_edges = train_graph[edge_type].edge_index.shape[1] if 'edge_index' in train_graph[edge_type] else 0\n",
    "    test_edges = test_graph[edge_type].edge_index.shape[1] if 'edge_index' in test_graph[edge_type] else 0\n",
    "    print(f\"  - {edge_type}: {train_edges} (train) | {test_edges} (test)\")\n",
    "\n",
    "#   Vérification des features (nodes et edges)\n",
    "for node_type in train_graph.node_types:\n",
    "    if 'x' in train_graph[node_type]:\n",
    "        print(f\"\\n  {node_type} features shape: {train_graph[node_type].x.shape} (train) | {test_graph[node_type].x.shape} (test)\")\n",
    "\n",
    "for edge_type in train_graph.edge_types:\n",
    "    if 'edge_attr' in train_graph[edge_type]:\n",
    "        print(f\"\\n  {edge_type} edge features shape: {train_graph[edge_type].edge_attr.shape} (train) | {test_graph[edge_type].edge_attr.shape} (test)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA disponible: True\n",
      "Nombre de GPUs: 1\n",
      "Nom du GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"CUDA disponible: {torch.cuda.is_available()}\")\n",
    "print(f\"Nombre de GPUs: {torch.cuda.device_count()}\")\n",
    "print(f\"Nom du GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'Aucun GPU détecté'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training GNN (HGTConv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training on: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, BatchNorm1d, Dropout\n",
    "from torch_geometric.nn import HGTConv\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\n Training on: {device}\")\n",
    "\n",
    "class DenseHGTGNN(torch.nn.Module):\n",
    "    def __init__(self, metadata, hidden_dim=256, out_dim=1, num_heads=8, num_layers=3, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "\n",
    "        #  Couches de HGTConv plus profondes\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.convs.append(HGTConv(hidden_dim, hidden_dim, metadata=metadata, heads=num_heads))\n",
    "\n",
    "        #  Normalisation et Résiduals\n",
    "        self.norms = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.norms.append(BatchNorm1d(hidden_dim))\n",
    "\n",
    "        #  Couche finale de classification\n",
    "        self.lin = Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x_dict = conv(x_dict, edge_index_dict)  # GNN Propagation\n",
    "            x_dict = {key: self.norms[i](x) for key, x in x_dict.items()}  # Normalisation\n",
    "            x_dict = {key: F.relu(x) for key, x in x_dict.items()}  # Activation ReLU\n",
    "            x_dict = {key: self.dropout(x) for key, x in x_dict.items()}  # Dropout\n",
    "        \n",
    "        x_dict = {key: self.lin(x) for key, x in x_dict.items()}  \n",
    "        return x_dict['session'].squeeze()  \n",
    "\n",
    "metadata = train_graph.metadata()\n",
    "model = DenseHGTGNN(metadata=metadata, hidden_dim=256, out_dim=1, num_heads=8, num_layers=3, dropout_rate=0.3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003, weight_decay=1e-4)\n",
    "\n",
    "train_loader = NeighborLoader(\n",
    "    train_graph,\n",
    "    num_neighbors={key: [15, 15, 10] for key in train_graph.edge_types}, \n",
    "    batch_size=512, \n",
    "    input_nodes=('session', torch.arange(train_graph['session'].num_nodes)),  \n",
    "    shuffle=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   Training on: cuda\n",
      "  GNN Model & DataLoader Ready!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Dropout\n",
    "from torch_geometric.nn import HGTConv\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "#   Vérifier si CUDA est disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\n   Training on: {device}\")\n",
    "\n",
    "#   1 Définition du Modèle GNN Dense\n",
    "class DenseHGTGNN(torch.nn.Module):\n",
    "    def __init__(self, metadata, hidden_dim=256, out_dim=1, num_heads=8, num_layers=3, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "\n",
    "        #   Couches HGTConv\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.convs.append(HGTConv(hidden_dim, hidden_dim, metadata=metadata, heads=num_heads))\n",
    "\n",
    "        #   Couche finale\n",
    "        self.lin = Linear(hidden_dim, out_dim)\n",
    "\n",
    "        #   Initialisation des poids\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        torch.nn.init.xavier_uniform_(self.lin.weight)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)  #   Propagation\n",
    "            x_dict = {key: F.relu(x) for key, x in x_dict.items()}  #   Activation\n",
    "            x_dict = {key: self.dropout(x) for key, x in x_dict.items()}  #   Dropout\n",
    "        \n",
    "        x_dict = {key: self.lin(x) for key, x in x_dict.items()}  \n",
    "        return x_dict['session'].squeeze()  \n",
    "\n",
    "#     Initialisation du Modèle\n",
    "metadata = train_graph.metadata()\n",
    "model = DenseHGTGNN(metadata=metadata, hidden_dim=256, out_dim=1, num_heads=8, num_layers=3, dropout_rate=0.3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003, weight_decay=1e-4)\n",
    "\n",
    "#   3 Chargement des Données (Neighbor Sampling)\n",
    "train_loader = NeighborLoader(\n",
    "    train_graph,\n",
    "    num_neighbors={key: [15, 15, 10] for key in train_graph.edge_types}, \n",
    "    batch_size=512, \n",
    "    input_nodes=('session', torch.arange(train_graph['session'].num_nodes)) if 'session' in train_graph.node_types else None,  \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(\"  GNN Model & DataLoader Ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Vérification des dimensions des entrées du modèle :\n",
      "   session: torch.Size([512, 1])\n",
      "   course: torch.Size([0, 18])\n"
     ]
    }
   ],
   "source": [
    "print(\"  Vérification des dimensions des entrées du modèle :\")\n",
    "for key, x in next(iter(train_loader)).x_dict.items():\n",
    "    print(f\"   {key}: {x.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'node_counters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnode_counters\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcourse\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Nombre total de cours: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_counters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcourse\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Taille attendue de `course.x`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(node_counters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcourse\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;250m \u001b[39m\u001b[38;5;241m18\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'node_counters' is not defined"
     ]
    }
   ],
   "source": [
    "if node_counters['course'] > 0:\n",
    "    print(f\"  Nombre total de cours: {node_counters['course']}\")\n",
    "    print(f\"  Taille attendue de `course.x`: {(node_counters['course'], 18)}\")\n",
    "else:\n",
    "    print(\"  Aucun cours détecté ! Vérifiez la présence des nœuds.\")\n",
    "\n",
    "# Ajout des features\n",
    "if len(course_features) > 0:\n",
    "    data['course'].x = torch.tensor(course_features, dtype=torch.float)\n",
    "else:\n",
    "    print(\"  `course.x` est vide ! Assurez-vous que les catégories de cours sont bien ajoutées.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Vérification des dimensions des entrées du modèle :\n",
      "   session: torch.Size([512, 1])\n",
      "   course: torch.Size([0, 18])\n",
      "\n",
      "  Entraînement du modèle...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (512x1 and 256x768)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#     Lancement de l'entraînement sur GPU\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  Entraînement du modèle...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Entraînement terminé !  \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[21], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, loader, optimizer, epochs)\u001b[0m\n\u001b[0;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#   Forward pass\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(out, batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msession\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#   Backpropagation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[20], line 37\u001b[0m, in \u001b[0;36mDenseHGTGNN.forward\u001b[1;34m(self, x_dict, edge_index_dict)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_dict, edge_index_dict):\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs:\n\u001b[1;32m---> 37\u001b[0m         x_dict \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m#   Propagation\u001b[39;00m\n\u001b[0;32m     38\u001b[0m         x_dict \u001b[38;5;241m=\u001b[39m {key: F\u001b[38;5;241m.\u001b[39mrelu(x) \u001b[38;5;28;01mfor\u001b[39;00m key, x \u001b[38;5;129;01min\u001b[39;00m x_dict\u001b[38;5;241m.\u001b[39mitems()}  \u001b[38;5;66;03m#   Activation\u001b[39;00m\n\u001b[0;32m     39\u001b[0m         x_dict \u001b[38;5;241m=\u001b[39m {key: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x) \u001b[38;5;28;01mfor\u001b[39;00m key, x \u001b[38;5;129;01min\u001b[39;00m x_dict\u001b[38;5;241m.\u001b[39mitems()}  \u001b[38;5;66;03m#   Dropout\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_geometric\\nn\\conv\\hgt_conv.py:184\u001b[0m, in \u001b[0;36mHGTConv.forward\u001b[1;34m(self, x_dict, edge_index_dict)\u001b[0m\n\u001b[0;32m    181\u001b[0m k_dict, q_dict, v_dict, out_dict \u001b[38;5;241m=\u001b[39m {}, {}, {}, {}\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# Compute K, Q, V over node types:\u001b[39;00m\n\u001b[1;32m--> 184\u001b[0m kqv_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkqv_lin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m kqv_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    186\u001b[0m     k, q, v \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor_split(val, \u001b[38;5;241m3\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_geometric\\nn\\dense\\linear.py:473\u001b[0m, in \u001b[0;36mHeteroDictLinear.forward\u001b[1;34m(self, x_dict)\u001b[0m\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, lin \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlins\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    472\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m x_dict:\n\u001b[1;32m--> 473\u001b[0m             out_dict[key] \u001b[38;5;241m=\u001b[39m \u001b[43mlin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_dict\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_geometric\\nn\\dense\\linear.py:147\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    142\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \n\u001b[0;32m    144\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m        x (torch.Tensor): The input features.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (512x1 and 256x768)"
     ]
    }
   ],
   "source": [
    "#   ... Fonction d'entraînement du modèle\n",
    "def train(model, loader, optimizer, epochs=50):\n",
    "    model.train()\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)  #   Réduction du LR chaque 10 epochs\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #   Forward pass\n",
    "            out = model(batch.x_dict, batch.edge_index_dict)\n",
    "            loss = F.binary_cross_entropy_with_logits(out, batch['session'].y.float())\n",
    "            \n",
    "            #   Backpropagation\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  #   Gradient Clipping\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"  Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(loader):.4f}, LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "#   5 Vérification avant entraînement\n",
    "print(\"\\n  Vérification des dimensions des entrées du modèle :\")\n",
    "for key, x in next(iter(train_loader)).x_dict.items():\n",
    "    print(f\"   {key}: {x.shape}\")\n",
    "\n",
    "#     Lancement de l'entraînement sur GPU\n",
    "print(\"\\n  Entraînement du modèle...\")\n",
    "train(model, train_loader, optimizer, epochs=50)\n",
    "print(\"  Entraînement terminé !  \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Nombre de nœuds dans chaque catégorie :\n",
      "  - user: 715 nœuds\n",
      "  - session: 26777 nœuds\n",
      "  - course: 247 nœuds\n",
      "  - action: 186345 nœuds\n",
      "  Aucune feature trouvée pour 'course' !\n",
      "  Arêtes User → Course: torch.Size([2, 2270612])\n"
     ]
    }
   ],
   "source": [
    "# Vérifier le nombre de nœuds\n",
    "print(f\"  Nombre de nœuds dans chaque catégorie :\")\n",
    "for node_type in data_pyg.node_types:\n",
    "    print(f\"  - {node_type}: {data_pyg[node_type].num_nodes} nœuds\")\n",
    "\n",
    "# Vérifier si `course.x` contient bien des features\n",
    "if 'course' in data_pyg and hasattr(data_pyg['course'], 'x'):\n",
    "    print(f\"  Features de 'course': {data_pyg['course'].x.shape}\")\n",
    "else:\n",
    "    print(\"  Aucune feature trouvée pour 'course' !\")\n",
    "\n",
    "# Vérifier si l'arête entre user et course existe bien\n",
    "if ('user', 'ENROLLED_IN', 'course') in data_pyg.edge_types:\n",
    "    print(f\"  Arêtes User → Course: {data_pyg[('user', 'ENROLLED_IN', 'course')].edge_index.shape}\")\n",
    "else:\n",
    "    print(\"  Aucun lien 'User → Course' trouvé !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'node_counters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnode_counters\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcourse\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m      2\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcourse\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(course_features, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'node_counters' is not defined"
     ]
    }
   ],
   "source": [
    "if node_counters['course'] > 0:\n",
    "    data['course'].x = torch.tensor(course_features, dtype=torch.float)\n",
    "else:\n",
    "    print(\"  Aucun nœud 'course' détecté, vérifiez la construction du graphe !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Vérification des dimensions des entrées du modèle :\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Vérification des dimensions des entrées du modèle :\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mbatch\u001b[49m\u001b[38;5;241m.\u001b[39mx_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Vérification des dimensions des entrées du modèle :\n",
      "   session: torch.Size([512, 1])\n",
      "   course: torch.Size([0, 18])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (512x1 and 256x768)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(loader)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, LR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscheduler\u001b[38;5;241m.\u001b[39mget_last_lr()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m#   Lancement de l'entraînement\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, loader, optimizer, epochs)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Vérification des dimensions de sortie\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Shape de la sortie du modèle: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msession\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[8], line 32\u001b[0m, in \u001b[0;36mDenseHGTGNN.forward\u001b[1;34m(self, x_dict, edge_index_dict)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_dict, edge_index_dict):\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs):\n\u001b[1;32m---> 32\u001b[0m         x_dict \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# GNN Propagation\u001b[39;00m\n\u001b[0;32m     33\u001b[0m         x_dict \u001b[38;5;241m=\u001b[39m {key: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorms[i](x) \u001b[38;5;28;01mfor\u001b[39;00m key, x \u001b[38;5;129;01min\u001b[39;00m x_dict\u001b[38;5;241m.\u001b[39mitems()}  \u001b[38;5;66;03m# Normalisation\u001b[39;00m\n\u001b[0;32m     34\u001b[0m         x_dict \u001b[38;5;241m=\u001b[39m {key: F\u001b[38;5;241m.\u001b[39mrelu(x) \u001b[38;5;28;01mfor\u001b[39;00m key, x \u001b[38;5;129;01min\u001b[39;00m x_dict\u001b[38;5;241m.\u001b[39mitems()}  \u001b[38;5;66;03m# Activation ReLU\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_geometric\\nn\\conv\\hgt_conv.py:184\u001b[0m, in \u001b[0;36mHGTConv.forward\u001b[1;34m(self, x_dict, edge_index_dict)\u001b[0m\n\u001b[0;32m    181\u001b[0m k_dict, q_dict, v_dict, out_dict \u001b[38;5;241m=\u001b[39m {}, {}, {}, {}\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# Compute K, Q, V over node types:\u001b[39;00m\n\u001b[1;32m--> 184\u001b[0m kqv_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkqv_lin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m kqv_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    186\u001b[0m     k, q, v \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor_split(val, \u001b[38;5;241m3\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_geometric\\nn\\dense\\linear.py:473\u001b[0m, in \u001b[0;36mHeteroDictLinear.forward\u001b[1;34m(self, x_dict)\u001b[0m\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, lin \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlins\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    472\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m x_dict:\n\u001b[1;32m--> 473\u001b[0m             out_dict[key] \u001b[38;5;241m=\u001b[39m \u001b[43mlin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_dict\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_geometric\\nn\\dense\\linear.py:147\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    142\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \n\u001b[0;32m    144\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m        x (torch.Tensor): The input features.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (512x1 and 256x768)"
     ]
    }
   ],
   "source": [
    "# Fonction d'entraînement\n",
    "def train(model, loader, optimizer, epochs=30):\n",
    "    model.train()\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)  # Réduction du LR chaque 10 epochs\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #   Vérification des dimensions des entrées AVANT le forward pass\n",
    "            print(\"  Vérification des dimensions des entrées du modèle :\")\n",
    "            for key, x in batch.x_dict.items():\n",
    "                print(f\"   {key}: {x.shape}\")\n",
    "\n",
    "            # Forward pass\n",
    "            out = model(batch.x_dict, batch.edge_index_dict)\n",
    "\n",
    "            # Vérification des dimensions de sortie\n",
    "            print(f\"  Shape de la sortie du modèle: {out.shape}, Labels: {batch['session'].y.shape}\")\n",
    "\n",
    "            loss = F.binary_cross_entropy_with_logits(out, batch['session'].y.float())\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  #   Gradient Clipping\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(loader):.4f}, LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "#   Lancement de l'entraînement\n",
    "train(model, train_loader, optimizer, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "def create_learning_graph(df):\n",
    "    # Création d'un graphe dirigé simple\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # 1. Pré-calculs\n",
    "    session_starts = df.groupby(['enroll_id', 'session_id'])['time'].min().reset_index()\n",
    "    session_starts = session_starts.sort_values(['enroll_id', 'time'])\n",
    "    \n",
    "    course_interactions = df.groupby(['username', 'course_id'])['action'].count().reset_index()\n",
    "    course_interactions = course_interactions.rename(columns={'action': 'action_count_per_course'})\n",
    "\n",
    "    # 2. Création des nœuds\n",
    "    unique_nodes = df.drop_duplicates()\n",
    "    for _, row in unique_nodes.iterrows():\n",
    "        G.add_node(row['username'], type='user')\n",
    "        G.add_node(row['course_id'], type='course', category=row['category'])\n",
    "        G.add_node(row['session_id'], type='session')\n",
    "        G.add_node(f\"{row['session_id']}_{row['action']}\", type='action')\n",
    "\n",
    "    # 3. Création des arêtes\n",
    "    # 3.1 User → Course\n",
    "    for _, row in course_interactions.iterrows():\n",
    "        G.add_edge(row['username'], \n",
    "                  row['course_id'],\n",
    "                  type='ENROLLED_IN',\n",
    "                  weight=row['action_count_per_course'])\n",
    "\n",
    "    # 3.2 User → Session\n",
    "    for _, row in df.drop_duplicates('session_id').iterrows():\n",
    "        G.add_edge(row['username'],\n",
    "                  row['session_id'],\n",
    "                  type='PARTICIPATES_IN',\n",
    "                  session_duration=row['session_duration'],\n",
    "                  action_frequency=row['action_frequency'])\n",
    "\n",
    "    # 3.3 Session → Action\n",
    "    for _, row in df.iterrows():\n",
    "        G.add_edge(row['session_id'],\n",
    "                  f\"{row['session_id']}_{row['action']}\",\n",
    "                  type='HAS_ACTION',\n",
    "                  timestamp=row['time'])\n",
    "\n",
    "    # 3.4 Action → Action\n",
    "    for session_id, session_group in df.groupby('session_id'):\n",
    "        actions_chronological = session_group.sort_values('time')\n",
    "        for i in range(len(actions_chronological)-1):\n",
    "            current = actions_chronological.iloc[i]\n",
    "            next_action = actions_chronological.iloc[i+1]\n",
    "            time_diff = (pd.to_datetime(next_action['time']) - \n",
    "                        pd.to_datetime(current['time'])).total_seconds()\n",
    "            \n",
    "            G.add_edge(f\"{session_id}_{current['action']}\",\n",
    "                      f\"{session_id}_{next_action['action']}\",\n",
    "                      type='FOLLOWS',\n",
    "                      time_diff=time_diff)\n",
    "\n",
    "    # 3.5 Session → Session\n",
    "    for enroll_id, group in session_starts.groupby('enroll_id'):\n",
    "        sessions = group['session_id'].tolist()\n",
    "        gaps = df[df['enroll_id'] == enroll_id].drop_duplicates('session_id')['session_gap'].tolist()\n",
    "        \n",
    "        for i in range(len(sessions)-1):\n",
    "            G.add_edge(sessions[i],\n",
    "                      sessions[i+1],\n",
    "                      type='SESSION_GAP',\n",
    "                      gap=gaps[i+1],\n",
    "                      enroll_id=enroll_id)\n",
    "\n",
    "    return G\n",
    "\n",
    "def analyze_graph(G):\n",
    "    print(\"\\nAnalyse du graphe:\")\n",
    "    print(f\"Nombre total de nœuds: {G.number_of_nodes()}\")\n",
    "    print(f\"Nombre total d'arêtes: {G.number_of_edges()}\")\n",
    "    \n",
    "    # Compter les différents types de nœuds\n",
    "    node_types = {}\n",
    "    for node in G.nodes(data=True):\n",
    "        node_type = node[1].get('type')\n",
    "        node_types[node_type] = node_types.get(node_type, 0) + 1\n",
    "    \n",
    "    print(\"\\nDistribution des types de nœuds:\")\n",
    "    for node_type, count in node_types.items():\n",
    "        print(f\"- {node_type}: {count}\")\n",
    "    \n",
    "    # Compter les différents types d'arêtes\n",
    "    edge_types = {}\n",
    "    for _, _, data in G.edges(data=True):\n",
    "        edge_type = data.get('type')\n",
    "        edge_types[edge_type] = edge_types.get(edge_type, 0) + 1\n",
    "    \n",
    "    print(\"\\nDistribution des types d'arêtes:\")\n",
    "    for edge_type, count in edge_types.items():\n",
    "        print(f\"- {edge_type}: {count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
